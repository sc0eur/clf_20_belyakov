{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Данные\n",
    "\n",
    "Данные в [архиве](https://drive.google.com/file/d/15o7fdxTgndoy6K-e7g8g1M2-bOOwqZPl/view?usp=sharing). В нём два файла:\n",
    "- `news_train.txt` тренировочное множество\n",
    "- `news_test.txt` тренировочное множество\n",
    "\n",
    "С некоторых новостных сайтов были загружены тексты новостей за период  несколько лет, причем каждая новость принаделжит к какой-то рубрике: `science`, `style`, `culture`, `life`, `economics`, `business`, `travel`, `forces`, `media`, `sport`.\n",
    "\n",
    "В каждой строке файла содержится метка рубрики, заголовок новостной статьи и сам текст статьи, например:\n",
    "\n",
    ">    **sport**&nbsp;&lt;tab&gt;&nbsp;**Сборная Канады по хоккею разгромила чехов**&nbsp;&lt;tab&gt;&nbsp;**Сборная Канады по хоккею крупно об...**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Задача\n",
    "\n",
    "1. Обработать данные, получив для каждого текста набор токенов\n",
    "Обработать токены с помощью (один вариант из трех):\n",
    "    - pymorphy2\n",
    "    - русского [snowball стеммера](https://www.nltk.org/howto/stem.html)\n",
    "    - [SentencePiece](https://github.com/google/sentencepiece) или [Huggingface Tokenizers](https://github.com/huggingface/tokenizers)\n",
    "    \n",
    "    \n",
    "2. Обучить word embeddings (fastText, word2vec, gloVe) на тренировочных данных. Можно использовать [gensim](https://radimrehurek.com/gensim/models/word2vec.html) . Продемонстрировать семантические ассоциации. \n",
    "\n",
    "3. Реализовать алгоритм классификации, посчитать точноть на тестовых данных, подобрать гиперпараметры. Метод векторизации выбрать произвольно - можно использовать $tf-idf$ с понижением размерности (см. scikit-learn), можно использовать обученные на предыдущем шаге векторные представления, можно использовать [предобученные модели](https://rusvectores.org/ru/models/). Имейте ввиду, что простое \"усреднение\" токенов в тексте скорее всего не даст положительных результатов. Нужно реализовать два алгоритмов из трех:\n",
    "     - SVM\n",
    "     - наивный байесовский классификатор\n",
    "     - логистическая регрессия\n",
    "    \n",
    "\n",
    "4.* Реализуйте классификацию с помощью нейросетевых моделей. Например [RuBERT](http://docs.deeppavlov.ai/en/master/features/models/bert.html) или [ELMo](https://rusvectores.org/ru/models/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import SnowballStemmer\n",
    "import string\n",
    "from gensim.models.fasttext import FastText\n",
    "import pymorphy2\n",
    "\n",
    "morph = pymorphy2.MorphAnalyzer()\n",
    "stoplist = stopwords.words(\"russian\") + list(string.punctuation) + [\"«\", \"»\"]\n",
    "sb = SnowballStemmer(language=\"russian\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv(\"../data/news_test.txt\", sep=\"\\t\", header=None)\n",
    "df_test.columns = [\"label\", \"title\", \"text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(\"../data/news_train.txt\", sep=\"\\t\", header=None)\n",
    "df_train.columns = [\"label\", \"title\", \"text\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# обработка с помощью pymorphy2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stop_and_stem(text_list):\n",
    "    res = []\n",
    "    for word in text_list:\n",
    "        if word not in stoplist:\n",
    "            res.append(morph.parse(word)[0].normal_form.replace(\".\", \"\"))\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['tokens'] = df_train[\"text\"].apply(lambda x: word_tokenize(x, language=\"russian\"))\n",
    "df_train[\"lem\"] = df_train['tokens'].apply(stop_and_stem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test[\"tokens\"] = df_test[\"text\"].apply(lambda x: word_tokenize(x, language=\"russian\"))\n",
    "df_test[\"lem\"] = df_test['tokens'].apply(stop_and_stem)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# обучение модели fastText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = FastText()\n",
    "model.build_vocab(sentences=df_train[\"lem\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train(sentences=df_train[\"lem\"], total_examples=len(df_train[\"lem\"]), epochs=20, workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "wv = model.wv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('нью-йоркский', 0.5693014860153198),\n",
       " ('нью-йорк', 0.5630447864532471),\n",
       " ('город', 0.5014321208000183),\n",
       " ('йорк', 0.49309042096138),\n",
       " ('сан-франциско', 0.4904010593891144)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wv.most_similar(positive=[\"санкт-петербург\", \"сша\"], negative=[\"россия\"], topn=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn import model_selection, naive_bayes, svm\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train[\"text_lem\"] = df_train[\"lem\"].apply(lambda x: ' '.join(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'нападать вашингтон кэпиталзти александр овечкин передать детский хоккейный школа автомобиль получить окончание матч звезда национальный хоккейный лига нхл о сообщаться официальный сайт лигиавтомобиль honda accord подарить хоккеист решение спонсор мероприятие игрок нхл пожертвовать машина спортивный школа nova cool cats special hockey inc который расположить штат вирджинияовечкин общаться 10-летний девочка анна чтоб синдром даун который заниматься школа являться поклонница спортсмен в сентябрь форвард пообедать вместе юный хоккеистка японский ресторанематч звезда нхл коламбус штат огайо завершиться победа команда джонатан тэйвз команда ник фолиньо счёт 17:12 овечкин выступать проиграть коллектив россиянин отметиться три результативный передача'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train[\"text_lem\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['word_count'] = df_train['lem'].apply(lambda x: len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    15000.000000\n",
       "mean       152.139067\n",
       "std         51.465810\n",
       "min          3.000000\n",
       "25%        117.000000\n",
       "50%        145.000000\n",
       "75%        179.000000\n",
       "max        832.000000\n",
       "Name: word_count, dtype: float64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['word_count'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# векторизация с помощью tf-idf и PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(max_features=2 ** 11)\n",
    "X = vectorizer.fit_transform(df_train[\"text_lem\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test[\"text_lem\"] = df_test[\"lem\"].apply(lambda x: ' '.join(x))\n",
    "X_test = vectorizer.transform(df_test[\"text_lem\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15000, 2048)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15000, 1657)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca = PCA(n_components=0.95, random_state=42)\n",
    "X_reduced = pca.fit_transform(X.toarray())\n",
    "X_reduced.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_reduced = pca.transform(X_test.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3000, 2048)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "Encoder = LabelEncoder()\n",
    "train_Y = Encoder.fit_transform(df_train[\"label\"])\n",
    "test_Y = Encoder.fit_transform(df_test[\"label\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Наивный байесовский классификатор"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NB accuracy:  0.841\n"
     ]
    }
   ],
   "source": [
    "Naive = naive_bayes.MultinomialNB()\n",
    "Naive.fit(X, train_Y)\n",
    "\n",
    "predictions_NB = Naive.predict(X_test)\n",
    "\n",
    "print(\"NB accuracy: \", accuracy_score(predictions_NB, test_Y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Логистическая регрессия с подбором параметров"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.858\n",
      "LogisticRegression(C=4, multi_class='multinomial', n_jobs=4, random_state=17)\n"
     ]
    }
   ],
   "source": [
    "hyper = {'C' : [1, 4, 10, 100],\n",
    "         'solver': ['lbfgs']}\n",
    "gd=GridSearchCV(estimator=\n",
    "                LogisticRegression(multi_class='multinomial', random_state=17, n_jobs=4),\n",
    "                param_grid=hyper)\n",
    "gd.fit(X_reduced, train_Y)\n",
    "print(gd.best_score_)\n",
    "print(gd.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR accuracy ->  0.8696666666666667\n"
     ]
    }
   ],
   "source": [
    "# lr = LogisticRegression(multi_class='multinomial', random_state=17)\n",
    "lr = gd.best_estimator_\n",
    "lr.fit(X_reduced, train_Y)\n",
    "predictions_lr = lr.predict(X_test_reduced)\n",
    "\n",
    "print(\"LR accuracy -> \", accuracy_score(predictions_lr, test_Y))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
